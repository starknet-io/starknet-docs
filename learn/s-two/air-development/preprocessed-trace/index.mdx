---
title: "Preprocessed trace"
---

<Warning>
This section and the following sections are intended for developers who have completed the [Writing a Simple AIR](../writing-a-simple-air/index.mdx) section or are already familiar with the workflow of creating an AIR. If you have not gone through the [Writing a Simple AIR](../writing-a-simple-air/index.mdx) section, we recommend you to do so first as the following sections gloss over a lot of boilerplate code.
</Warning>

For those of you who have completed the [Writing a Simple AIR](../writing-a-simple-air/index.mdx) tutorial, you should now be familiar with the concept of a trace as a table of integers that are filled in by the prover (we will now refer to this as the **original trace**).

In addition to the original trace, S-two also has a concept of a **preprocessed trace**, which is a table whose values are fixed and therefore cannot be arbitrarily chosen by the prover.
In other words, these are columns whose values are known in advance of creating a proof and essentially agreed upon by both the prover and the verifier.
One of the use cases of the preprocessed trace is as _a selector for different constraints_.
Remember that in an AIR, the same constraints are applied to every row of the trace?
If we go back to the spreadsheet analogy, this means that we can't create a spreadsheet that runs different computations for different rows.
We can get around this issue by composing multiple constraints using a selector column as part of the preprocessed trace.
For example, let's say we want to create a constraint that runs different computations for the first 2 rows and the next 2 rows.
We can do this by using a preprocessed trace that has value 1 for the first 2 rows and 0 for the next 2 rows, essentially as a selector for the first 2 rows.
The resulting single constraint composes the two different constraints by adding them together:
$$
(1 - \text{preprocessed\_trace}) * \text{constraint\_1} + \text{preprocessed\_trace} * \text{constraint\_2}=0
$$

<Frame caption="Figure 1: Preprocessed trace as a selector">
  <img src="/learn/s-two/air-development/preprocessed-trace/preprocessed-trace-selector.png" />
</Frame>

Another use case is to use the preprocessed trace for _expressing constant values used in the constraints_.
For example, when creating a hash function in an AIR, we often need to use round constants, which the verifier needs to be able to verify or the resulting hash may be invalid.
We can also "look up" the constant values as an optimization technique, which we will discuss in more detail in the next section.
In this section, we will explore how to implement a preprocessed trace as a selector, and we will implement the simplest form: a single `isFirst` column, where the value is 1 for the first row and 0 for all other rows.

<Note>
Boilerplate code is omitted for brevity. Please refer to the [full example code](https://github.com/zksecurity/stwo/blob/main/stwo-examples/examples/preprocessed_trace.rs) for the full implementation.
</Note>
```rust
struct IsFirstColumn {
    pub log_size: u32,
}

impl IsFirstColumn {
    pub fn new(log_size: u32) -> Self {
        Self { log_size }
    }

    pub fn gen_column(&self) -> CircleEvaluation<SimdBackend, M31, BitReversedOrder> {
        let mut col = BaseColumn::zeros(1 << self.log_size);
        col.set(0, M31::from(1));
        CircleEvaluation::new(CanonicCoset::new(self.log_size).circle_domain(), col)
    }

    pub fn id(&self) -> PreProcessedColumnId {
        PreProcessedColumnId {
            id: format!("is_first_{}", self.log_size),
        }
    }
}
```

First, we need to define a `IsFirstColumn` struct that will be used as a preprocessed trace.
We will use the `gen_column()` function to generate a `CircleEvaluation` struct that is 1 for the first row and 0 for all other rows.
The `id()` function is needed to identify this column when evaluating the constraints.
```rust
fn main() {
    let log_size = LOG_N_LANES;

    // Config for FRI and PoW
    let config = PcsConfig::default();

    // Precompute twiddles for evaluating and interpolating the trace
    let twiddles = SimdBackend::precompute_twiddles(
        CanonicCoset::new(
            log_size + CONSTRAINT_EVAL_BLOWUP_FACTOR + config.fri_config.log_blowup_factor,
        )
        .circle_domain()
        .half_coset,
    );

    // Create the channel and commitment scheme
    let channel = &mut Blake2sChannel::default();
    let mut commitment_scheme =
        CommitmentSchemeProver::<SimdBackend, Blake2sMerkleChannel>::new(config, &twiddles);

    // Create and commit to the preprocessed trace
    let is_first_column = IsFirstColumn::new(log_size);
    let mut tree_builder = commitment_scheme.tree_builder();
    tree_builder.extend_evals(vec![is_first_column.gen_column()]);
    tree_builder.commit(channel);

    // Commit to the size of the trace
    channel.mix_u64(log_size as u64);

    // Create and commit to the original trace
    let trace = gen_trace(log_size);
    let mut tree_builder = commitment_scheme.tree_builder();
    tree_builder.extend_evals(trace);
    tree_builder.commit(channel);
}
```

Then, in our main function, we will create and commit to the preprocessed and original traces.
For those of you who are curious about why we need to commit to the trace, please refer to the [Committing to the Trace Polynomials](../writing-a-simple-air/committing-to-the-trace-polynomials.mdx) section.

```rust
struct TestEval {
    is_first_id: PreProcessedColumnId,
    log_size: u32,
}

impl FrameworkEval for TestEval {
    fn log_size(&self) -> u32 {
        self.log_size
    }

    fn max_constraint_log_degree_bound(&self) -> u32 {
        self.log_size + CONSTRAINT_EVAL_BLOWUP_FACTOR
    }

    fn evaluate<E: EvalAtRow>(&self, mut eval: E) -> E {
        let is_first = eval.get_preprocessed_column(self.is_first_id.clone());

        let col_1 = eval.next_trace_mask();
        let col_2 = eval.next_trace_mask();
        let col_3 = eval.next_trace_mask();

        // If is_first is 1, then the constraint is col_1 * col_2 - col_3 = 0
        // If is_first is 0, then the constraint is col_1 * col_2 + col_1 - col_3 = 0
        eval.add_constraint(
            (col_1.clone() * col_2.clone() - col_3.clone()) * is_first.clone()
                + (col_1.clone() * col_2.clone() + col_1.clone() - col_3.clone())
                    * (E::F::from(M31::from(1)) - is_first.clone()),
        );

        eval
    }
}
```

Now that we have the traces, we need to create a struct that contains the logic for evaluating the constraints.
As mentioned before, we need to use the `is_first_id` field to retrieve the row value of the `IsFirstColumn` struct.
Then, we compose two constraints using the `IsFirstColumn` row value as a selector and adding them together.

If you're unfamiliar with how `max_constraint_log_degree_bound(&self)` should be implemented, please refer to [this note](../writing-a-simple-air/constraints-over-trace-polynomials.mdx#max_constraint_log_degree_bound).
```rust
fn main() {
    // ... previous setup code ...

    // Create a component
    let component = FrameworkComponent::<TestEval>::new(
        &mut TraceLocationAllocator::default(),
        TestEval {
            is_first_id: is_first_column.id(),
            log_size,
        },
        QM31::zero(),
    );

    // Prove
    let proof = prove(&[&component], channel, commitment_scheme).unwrap();

    // Verify
    let channel = &mut Blake2sChannel::default();
    let commitment_scheme = &mut CommitmentSchemeVerifier::<Blake2sMerkleChannel>::new(config);
    let sizes = component.trace_log_degree_bounds();

    commitment_scheme.commit(proof.commitments[0], &sizes[0], channel);
    channel.mix_u64(log_size as u64);
    commitment_scheme.commit(proof.commitments[1], &sizes[1], channel);

    verify(&[&component], channel, commitment_scheme, proof).unwrap();
}
```

